{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'data/question_vocab.json'\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "import bisect\n",
    "from tqdm import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import programs\n",
    "from modify_program import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Num of questions:  1075062\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "questions = []\n",
    "for split in ['val_balanced', 'train_balanced']:\n",
    "    dataset = json.load(open(os.path.join(dataroot, \"questions1.2/%s_questions.json\"%split)))\n",
    "    for k, v in dataset.items():\n",
    "        v['qid'] = k\n",
    "    dataset = dataset.values()\n",
    "    update_program(dataset)\n",
    "    questions.extend(dataset)\n",
    "print('Num of questions: ', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len of args:  2\n",
      "max len of program:  17\n",
      "operation vocab:  15\n",
      "argument vocab:  2676\n"
     ]
    }
   ],
   "source": [
    "all_programs = [q['semantic'] for q in questions]\n",
    "all_operations = [op['operation'] for program in all_programs for op in program]\n",
    "all_arguments = [arg for program in all_programs for op in program for arg in op['argument']]\n",
    "\n",
    "\n",
    "print('max len of args: ', max([len(op['argument']) for program in all_programs for op in program]))\n",
    "print('max len of program: ', max([len(program) for program in all_programs]))\n",
    "\n",
    "operations_count = Counter(all_operations)\n",
    "arguments_count = Counter(all_arguments)\n",
    "\n",
    "operation_vocab = ['UNK', 'START', 'END'] + list(sorted(operations_count))\n",
    "argument_vocab = ['UNK', 'START', 'END'] + list(sorted(arguments_count))\n",
    "\n",
    "json.dump(operation_vocab, open('data/operation_vocab.json', 'w'), indent=2)\n",
    "json.dump(argument_vocab, open('data/argument_vocab.json', 'w'), indent=2)\n",
    "print('operation vocab: ', len(operation_vocab))\n",
    "print('argument vocab: ', len(argument_vocab))\n",
    "\n",
    "# I found some strange arguments in questions like 'What is she doing?', \n",
    "# these arguments are related to the last operation 'query'.\n",
    "# example qids: 00272272\n",
    "# I just leave them alone\n",
    "strange_args = [\"15\", \"16\", \"18\", \"24\", \"25\", \"27\", \"31\", \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len of question: 28\n",
      "question vocab:  2857\n"
     ]
    }
   ],
   "source": [
    "all_questions = [q['question'] for q in questions]\n",
    "words_count = Counter()\n",
    "max_len = 0\n",
    "for sentence in all_questions:\n",
    "    words = tokenize(sentence)\n",
    "    if len(words) > max_len:\n",
    "        max_len = len(words)\n",
    "    words_count.update(words)\n",
    "print('max len of question:', max_len)\n",
    "question_vocab = ['UNK', 'START', 'END'] + list(sorted(words_count))\n",
    "print('question vocab: ', len(question_vocab))\n",
    "json.dump(question_vocab, open('data/question_vocab.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embedding_init(idx2word, glove_file='data/glove.6B.300d.txt'):\n",
    "    word2emb = {}\n",
    "    with open(glove_file, 'r') as f:\n",
    "        entries = f.readlines()\n",
    "    emb_dim = len(entries[0].split(' ')) - 1\n",
    "    print('embedding dim is %d' % emb_dim)\n",
    "    #weights = np.zeros((len(idx2word), emb_dim), dtype=np.float32)\n",
    "    weights = np.random.uniform(-1, 1, (len(idx2word), emb_dim)).astype(np.float32)\n",
    "\n",
    "    for entry in entries:\n",
    "        vals = entry.split(' ')\n",
    "        word = vals[0]\n",
    "        vals = list(map(float, vals[1:]))\n",
    "        word2emb[word] = np.array(vals)\n",
    "    for idx, word in enumerate(idx2word):\n",
    "        if word not in word2emb:\n",
    "            print('Unseen: ', word)\n",
    "            continue\n",
    "        weights[idx] = word2emb[word]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding dim is 300\n",
      "Unseen:  UNK\n",
      "Unseen:  START\n",
      "Unseen:  END\n",
      "Unseen:  asparaguss\n",
      "Unseen:  avocadoes\n",
      "Unseen:  bronwy\n",
      "Unseen:  burritoes\n",
      "Unseen:  cactuss\n",
      "Unseen:  celeries\n",
      "Unseen:  drainer\n",
      "Unseen:  drainers\n",
      "Unseen:  elmoes\n",
      "Unseen:  hippoes\n",
      "Unseen:  legoes\n",
      "Unseen:  logoes\n",
      "Unseen:  meatballss\n",
      "Unseen:  mooses\n",
      "Unseen:  mousess\n",
      "Unseen:  octopodes\n",
      "Unseen:  ottomen\n",
      "Unseen:  pianoes\n",
      "Unseen:  plier\n",
      "Unseen:  puppys\n",
      "Unseen:  snowpants\n",
      "Unseen:  tacoes\n",
      "Unseen:  tshirt\n"
     ]
    }
   ],
   "source": [
    "init_weights = create_glove_embedding_init(question_vocab)\n",
    "init_weights /= np.sqrt(np.sum(init_weights**2, axis=1, keepdims=True))\n",
    "np.save('data/question_word_embedding_glove_init', init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer vocab:  1843\n"
     ]
    }
   ],
   "source": [
    "all_answers = [q['answer'] for q in questions]\n",
    "answers_count = Counter(all_answers)\n",
    "answer_vocab = ['UNK'] + list(sorted(answers_count)) # 'UNK' -> 'I do not know the answer'\n",
    "json.dump(answer_vocab, open('data/answer_vocab.json', 'w'), indent=2)\n",
    "print('answer vocab: ', len(answer_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('left', ('to the left of', 'to the right of')): 21024,\n",
      "         ('right', ('to the right of', 'to the left of')): 20931,\n",
      "         ('front', ('in front of', 'behind')): 489,\n",
      "         ('wooden', ('wood', 'metal')): 220,\n",
      "         ('metallic', ('metal', 'wood')): 134,\n",
      "         ('metallic', ('metal', 'porcelain')): 11,\n",
      "         ('ceramic', ('porcelain', 'metal')): 5,\n",
      "         ('ceramic', ('porcelain', 'wood')): 2,\n",
      "         ('front', ('standing in front of', 'standing behind')): 1})\n"
     ]
    }
   ],
   "source": [
    "# ideally, the gt answer should be included in the choices of 'choose' operation,\n",
    "# but I found some exceptions in the dataset.\n",
    "# based on observation of the results, \n",
    "\n",
    "choose_arguments = []\n",
    "for q in questions:\n",
    "    program = q['semantic']\n",
    "    if 'choose' not in ' '.join([x['operation'] for x in program]):\n",
    "        continue\n",
    "    assert 'choose' in program[-1]['operation'], program\n",
    "    argument = program[-1]['argument']\n",
    "    # choose healthier\n",
    "    if len(argument) == 0:\n",
    "        argument = [program[dep]['argument'][0] for dep in program[-1]['dependencies']]\n",
    "    if len(argument) >= 3:\n",
    "        argument = argument[1:3]\n",
    "    if q['answer'] not in argument:\n",
    "        choose_arguments.append((q['answer'], tuple(argument)))\n",
    "        \n",
    "pprint(Counter(choose_arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
